{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stpwords(sent):\n",
    "#{\n",
    "    stp_wrds = set(stopwords.words('english'))    # retrieving unique stop words in english.\n",
    "    wrd_tkns = nltk.word_tokenize(sent)       # tokenize sentence passed to this fn.\n",
    "    \n",
    "    filtered_sentence = []                  # initializing an empty list for storing key words (excluding stop words).\n",
    "    \n",
    "    for wrd in wrd_tkns:\n",
    "        if wrd not in stp_wrds:             # if the word is a stop word it will not be added to the filtered list.\n",
    "            filtered_sentence.append(wrd)\n",
    "            \n",
    "    return filtered_sentence                # returning the list without stop-words of english language.\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sense_def(wrd_lst):\n",
    "#{\n",
    "    sense_def_wrd_lst = []\n",
    "    \n",
    "    for wrd in wrd_lst:\n",
    "        for sense in wordnet.synsets(wrd.lower()):\n",
    "            sense_def_wrd_lst.append(remove_stpwords(sense.definition()))\n",
    "    \n",
    "    return set(sense_def_wrd_lst)\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_sense(wrd, company):\n",
    "#{\n",
    "    sense_def_wrd_set = get_sense_def(company)\n",
    "    \n",
    "    max_overlap = -1                   # initialized as -1, cause overlap may remain 0 after finding the \n",
    "                                       # intersection b/w sense definition and the word, for all the senses.\n",
    "                                       # In such a case no sense definition will be returned. Hence, initializing \n",
    "                                       # it as -1 so that the 1st sense is returned. \n",
    "                                       # (value of overlap = 0 and max_overlap = -1).\n",
    "    best_sense = ''                    # initializing variable.\n",
    "        \n",
    "    for sense in wordnet.synsets(wrd.lower()):\n",
    "    #{\n",
    "        overlap = set(remove_stpwords(nltk.word_tokenize(sense.definition()))).intersection(sense_def_wrd_set)\n",
    "        \n",
    "        if overlap > max_overlap:            # if another sense has more common words, then new sense is \n",
    "            max_overlap = overlap            # assigned to the best_sense variable to hold the sense till a \n",
    "            best_sense = sense.definition()  # better one is identified.\n",
    "    #}\n",
    "            \n",
    "    return best_sense\n",
    "#}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
