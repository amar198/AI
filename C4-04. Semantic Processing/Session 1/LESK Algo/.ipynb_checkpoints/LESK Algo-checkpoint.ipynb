{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stpwords(sent):\n",
    "    stp_wrds = set(stopwords.words('english'))    # retrieving unique stop words in english.\n",
    "    wrd_tkns = nltk.word_tokenize(sent)       # tokenize sentence passed to this fn.\n",
    "    \n",
    "    filtered_sentence = []                  # initializing an empty list for storing key words (excluding stop words).\n",
    "    \n",
    "    for wrd in wrd_tkns:\n",
    "        if wrd not in stp_wrds:             # if the word is a stop word it will not be added to the filtered list.\n",
    "            filtered_sentence.append(wrd)\n",
    "            \n",
    "    return filtered_sentence                # returning the list without stop-words of english language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LESK algo returns the best definition of the sense in which the words are supposed to be used.\n",
    "# it returns a list which contains Tuples with word and its definition.\n",
    "# E.g.\n",
    "# [\n",
    "#     (word1, best definition of word1), - Tuple 1\n",
    "#     (word2, best definition of word2), - Tuple 2\n",
    "#     ...\n",
    "# ]\n",
    "\n",
    "# List of parameters passed to the LESK algo fn.\n",
    "# words: the list of words for which sense definition needs to be found.\n",
    "# sents: the sentence in which the association b/w word and sense will be found.\n",
    "\n",
    "def lesk_algo(words, sent):\n",
    "    wrd_def = []                           # var in which word and its definition will be stored.\n",
    "    split_sent = remove_stpwords(sent.lower())     # splitting the sentence and removing the stop words.\n",
    "        \n",
    "    for word in words:                     # finding synsets for each word passed in the 'words' variable.\n",
    "    # {\n",
    "        max_overlap = -1                   # initialized as -1, cause overlap may remain 0 after finding the \n",
    "                                           # intersection b/w sense definition and the word, for all the senses.\n",
    "                                           # In such a case no sense definition will be returned. Hence, initializing \n",
    "                                           # it as -1 so that the 1st sense is returned. \n",
    "                                           # (value of overlap = 0 and max_overlap = -1).\n",
    "        best_sense = ''                    # initializing variable.\n",
    "        \n",
    "        for sense in wordnet.synsets(word.lower()):\n",
    "        # {\n",
    "            overlap = len(                    # finding the length of intersected words and assigning it to a var.\n",
    "                set(                          \n",
    "                    nltk.word_tokenize(sense.definition()) # finding the length of unique words in the sense \n",
    "                                                           # definition text.\n",
    "                ).intersection(                            # finding the words which intersets with the words\n",
    "                    split_sent                             # retrieved from the sentences passed to this fn.\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            print('%s  %s' % (word, sense.definition()))\n",
    "\n",
    "            if overlap > max_overlap:            # if another sense has more common words, then new sense is \n",
    "                max_overlap = overlap            # assigned to the best_sense variable to hold the sense till a \n",
    "                best_sense = sense.definition()  # better one is identified.\n",
    "        # } End of sense for-loop.\n",
    "        \n",
    "        wrd_def.append(best_sense)\n",
    "    # } End of word for-loop\n",
    "    \n",
    "    return list(zip(words, wrd_def))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LESK algo returns the best definition of the sense in which the words are supposed to be used.\n",
    "# it returns a list which contains Tuples with word and its definition.\n",
    "# E.g.\n",
    "# [\n",
    "#     (word1, best definition of word1), - Tuple 1\n",
    "#     (word2, best definition of word2), - Tuple 2\n",
    "#     ...\n",
    "# ]\n",
    "\n",
    "# List of parameters passed to the LESK algo fn.\n",
    "# sents: the sentence in which the association b/w word and sense will be found.\n",
    "\n",
    "def lesk_algo_sent(sent):\n",
    "    wrd_def = []                           # var in which word and its definition will be stored.\n",
    "    wrds4def = split_sent = remove_stpwords(sent.lower())     # splitting the sentence and removing the stop words.\n",
    "    \n",
    "    wrd_lst = []\n",
    "    prev_next_wrd = []\n",
    "    \n",
    "    for key, wrd in enumerate(split_sent):\n",
    "        if key == 0:\n",
    "            prev_next_wrd = [split_sent[key+1]]\n",
    "            \n",
    "        elif key > 0 and key < (len(split_sent)-1):\n",
    "            prev_next_wrd = [split_sent[key-1], split_sent[key+1]]\n",
    "            \n",
    "        elif key == (len(split_sent)-1):\n",
    "            prev_next_wrd = [split_sent[key-1]]\n",
    "            \n",
    "        wrd_lst.append(tuple([prev_next_wrd, wrd]))\n",
    "        \n",
    "    print(wrd_lst)\n",
    "    \n",
    "    for word in split_sent:                     # finding synsets for each word passed in the 'words' variable.\n",
    "    # {\n",
    "        max_overlap = -1                   # initialized as -1, cause overlap may remain 0 after finding the \n",
    "                                           # intersection b/w sense definition and the word, for all the senses.\n",
    "                                           # In such a case no sense definition will be returned. Hence, initializing \n",
    "                                           # it as -1 so that the 1st sense is returned. \n",
    "                                           # (value of overlap = 0 and max_overlap = -1).\n",
    "        best_sense = ''                    # initializing variable.\n",
    "        \n",
    "        for sense in wordnet.synsets(word.lower()):\n",
    "        # {\n",
    "            overlap = len(                    # finding the length of intersected words and assigning it to a var.\n",
    "                set(                          \n",
    "                    nltk.word_tokenize(sense.definition()) # finding the length of unique words in the sense \n",
    "                                                           # definition text.\n",
    "                ).intersection(                            # finding the words which intersets with the words\n",
    "                    wrds4def                               # retrieved from the sentences passed to this fn.\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if overlap > max_overlap:            # if another sense has more common words, then new sense is \n",
    "                max_overlap = overlap            # assigned to the best_sense variable to hold the sense till a \n",
    "                best_sense = sense.definition()  # better one is identified.\n",
    "                \n",
    "        # } End of sense for-loop.        \n",
    "        \n",
    "        wrds4def = wrds4def + remove_stpwords(best_sense)\n",
    "        wrd_def.append(best_sense)\n",
    "    # } End of word for-loop\n",
    "    \n",
    "    #print(wrds4def)\n",
    "    \n",
    "    return list(zip(split_sent, wrd_def))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LESK algo returns the best definition of the sense in which the words are supposed to be used.\n",
    "# it returns a list which contains Tuples with word and its definition.\n",
    "# E.g.\n",
    "# [\n",
    "#     (word1, best definition of word1), - Tuple 1\n",
    "#     (word2, best definition of word2), - Tuple 2\n",
    "#     ...\n",
    "# ]\n",
    "\n",
    "# List of parameters passed to the LESK algo fn.\n",
    "# sents: the sentence in which the association b/w word and sense will be found.\n",
    "\n",
    "def lesk_algo_sent(sent):\n",
    "    wrd_def = []                           # var in which word and its definition will be stored.\n",
    "    wrds4def = split_sent = remove_stpwords(sent.lower())     # splitting the sentence and removing the stop words.\n",
    "    \n",
    "    wrd_lst = []\n",
    "    prev_next_wrd = []\n",
    "    \n",
    "    for key, wrd in enumerate(split_sent):\n",
    "        if key == 0:\n",
    "            prev_next_wrd = [split_sent[key+1]]\n",
    "            \n",
    "        elif key > 0 and key < (len(split_sent)-1):\n",
    "            prev_next_wrd = [split_sent[key-1], split_sent[key+1]]\n",
    "            \n",
    "        elif key == (len(split_sent)-1):\n",
    "            prev_next_wrd = [split_sent[key-1]]\n",
    "            \n",
    "        wrd_lst.append(tuple([prev_next_wrd, wrd]))\n",
    "    \n",
    "    for word in wrd_lst:                     # finding synsets for each word passed in the 'words' variable.\n",
    "    # {\n",
    "        max_overlap = -1                   # initialized as -1, cause overlap may remain 0 after finding the \n",
    "                                           # intersection b/w sense definition and the word, for all the senses.\n",
    "                                           # In such a case no sense definition will be returned. Hence, initializing \n",
    "                                           # it as -1 so that the 1st sense is returned. \n",
    "                                           # (value of overlap = 0 and max_overlap = -1).\n",
    "        best_sense = ''                    # initializing variable.\n",
    "        \n",
    "        print('%s  -> %s' % (word[0], word[1]))\n",
    "        \n",
    "        #for sense in wordnet.synsets(word[1].lower()):\n",
    "        ## {\n",
    "        #    overlap = len(                    # finding the length of intersected words and assigning it to a var.\n",
    "        #        set(                          \n",
    "        #            nltk.word_tokenize(sense.definition()) # finding the length of unique words in the sense \n",
    "        #                                                   # definition text.\n",
    "        #        ).intersection(                            # finding the words which intersets with the words\n",
    "        #            wrds4def                               # retrieved from the sentences passed to this fn.\n",
    "        #        )\n",
    "        #    )\n",
    "#\n",
    "        #    if overlap > max_overlap:            # if another sense has more common words, then new sense is \n",
    "        #        max_overlap = overlap            # assigned to the best_sense variable to hold the sense till a \n",
    "        #        best_sense = sense.definition()  # better one is identified.\n",
    "        #        \n",
    "        ## } End of sense for-loop.        \n",
    "        #\n",
    "        #wrds4def = wrds4def + remove_stpwords(best_sense)\n",
    "        #wrd_def.append(best_sense)\n",
    "    # } End of word for-loop\n",
    "    \n",
    "    #print(wrds4def)\n",
    "    \n",
    "    return list(zip(split_sent, wrd_def))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The frog is jumping around the bank of the river\"\n",
    "words = ['bank', 'jumping', 'leaping', 'frog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank  sloping land (especially the slope beside a body of water)\n",
      "bank  a financial institution that accepts deposits and channels the money into lending activities\n",
      "bank  a long ridge or pile\n",
      "bank  an arrangement of similar objects in a row or in tiers\n",
      "bank  a supply or stock held in reserve for future use (especially in emergencies)\n",
      "bank  the funds held by a gambling house or the dealer in some gambling games\n",
      "bank  a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "bank  a container (usually with a slot in the top) for keeping money at home\n",
      "bank  a building in which the business of banking transacted\n",
      "bank  a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
      "bank  tip laterally\n",
      "bank  enclose with a bank\n",
      "bank  do business with a bank or keep an account at a bank\n",
      "bank  act as the banker in a game or in gambling\n",
      "bank  be in the banking business\n",
      "bank  put into a bank account\n",
      "bank  cover with ashes so to control the rate of burning\n",
      "bank  have confidence or faith in\n",
      "jumping  the act of participating in an athletic competition in which you must jump\n",
      "jumping  the act of jumping; propelling yourself off the ground\n",
      "jumping  move forward by leaps and bounds\n",
      "jumping  move or jump suddenly, as if in surprise or alarm\n",
      "jumping  make a sudden physical attack on\n",
      "jumping  increase suddenly and significantly\n",
      "jumping  be highly noticeable\n",
      "jumping  enter eagerly into\n",
      "jumping  rise in rank or status\n",
      "jumping  jump down from an elevated point\n",
      "jumping  run off or leave the rails\n",
      "jumping  jump from an airplane and descend with a parachute\n",
      "jumping  cause to jump or leap\n",
      "jumping  start (a car engine whose battery is dead) by connecting it to another car's battery\n",
      "jumping  bypass\n",
      "jumping  pass abruptly from one state or topic to another\n",
      "jumping  go back and forth; swing back and forth between two states or conditions\n",
      "leaping  a light, self-propelled movement upwards or forwards\n",
      "leaping  move forward by leaps and bounds\n",
      "leaping  pass abruptly from one state or topic to another\n",
      "leaping  jump down from an elevated point\n",
      "leaping  cause to jump or leap\n",
      "frog  any of various tailless stout-bodied amphibians with long hind limbs for leaping; semiaquatic and terrestrial species\n",
      "frog  a person of French descent\n",
      "frog  a decorative loop of braid or cord\n",
      "frog  hunt frogs for food\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('bank', 'enclose with a bank'),\n",
       " ('jumping', 'the act of jumping; propelling yourself off the ground'),\n",
       " ('leaping', 'a light, self-propelled movement upwards or forwards'),\n",
       " ('frog',\n",
       "  'any of various tailless stout-bodied amphibians with long hind limbs for leaping; semiaquatic and terrestrial species')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesk_algo(words, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jumping']  -> frog\n",
      "['frog', 'around']  -> jumping\n",
      "['jumping', 'bank']  -> around\n",
      "['around', 'river']  -> bank\n",
      "['bank']  -> river\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ['frog', 'jumping', 'around', 'bank', 'river']\n",
    "lesk_algo_sent(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
